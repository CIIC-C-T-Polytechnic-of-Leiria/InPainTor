digraph {
	graph [size="82.35,82.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	129301091126384 [label="
 (1, 3, 512, 512)" fillcolor=darkolivegreen1]
	129301097698336 [label=SigmoidBackward0]
	129301097698048 -> 129301097698336
	129301097698048 [label=NativeBatchNormBackward0]
	129301097698192 -> 129301097698048
	129301097698192 [label=ConvolutionBackward0]
	129301097697904 -> 129301097698192
	129301097697904 [label=GeluBackward0]
	129301097697760 -> 129301097697904
	129301097697760 [label=ConvolutionBackward0]
	129301097697664 -> 129301097697760
	129301097697664 [label=GeluBackward0]
	129301097693296 -> 129301097697664
	129301097693296 [label=ConvolutionBackward0]
	129301097693392 -> 129301097693296
	129301097693392 [label=NativeBatchNormBackward0]
	129301097693584 -> 129301097693392
	129301097693584 [label=GeluBackward0]
	129301097693776 -> 129301097693584
	129301097693776 [label=ConvolutionBackward0]
	129301097693872 -> 129301097693776
	129301097693872 [label=ConvolutionBackward0]
	129301097705152 -> 129301097693872
	129301097705152 [label=CatBackward0]
	129301097705296 -> 129301097705152
	129301097705296 [label=GeluBackward0]
	129301097705392 -> 129301097705296
	129301097705392 [label=ConvolutionBackward0]
	129301097705488 -> 129301097705392
	129301097705488 [label=CatBackward0]
	129301097705680 -> 129301097705488
	129301097705680 [label=MulBackward0]
	129301097705056 -> 129301097705680
	129301097705056 [label=SoftmaxBackward0]
	129301097704912 -> 129301097705056
	129301097704912 [label=DivBackward0]
	129301097704816 -> 129301097704912
	129301097704816 [label=UnsafeViewBackward0]
	129301097704720 -> 129301097704816
	129301097704720 [label=BmmBackward0]
	129301097704624 -> 129301097704720
	129301097704624 [label=ViewBackward0]
	129301097704480 -> 129301097704624
	129301097704480 [label=ExpandBackward0]
	129301097704384 -> 129301097704480
	129301097704384 [label=NativeBatchNormBackward0]
	129301097704288 -> 129301097704384
	129301097704288 [label=ConvolutionBackward0]
	129301097704096 -> 129301097704288
	129301097704096 [label=NativeBatchNormBackward0]
	129301097704000 -> 129301097704096
	129301097704000 [label=GeluBackward0]
	129301097703520 -> 129301097704000
	129301097703520 [label=ConvolutionBackward0]
	129301097703424 -> 129301097703520
	129301097703424 [label=ConvolutionBackward0]
	129301097703232 -> 129301097703424
	129301097703232 [label=CatBackward0]
	129301097703088 -> 129301097703232
	129301097703088 [label=NativeBatchNormBackward0]
	129301097702944 -> 129301097703088
	129301097702944 [label=GeluBackward0]
	129301097702752 -> 129301097702944
	129301097702752 [label=ConvolutionBackward0]
	129301097702656 -> 129301097702752
	129301097702656 [label=ConvolutionBackward0]
	129301097702464 -> 129301097702656
	129301097702464 [label=CatBackward0]
	129301097702320 -> 129301097702464
	129301097702320 [label=NativeBatchNormBackward0]
	129301097702176 -> 129301097702320
	129301097702176 [label=GeluBackward0]
	129301097697472 -> 129301097702176
	129301097697472 [label=ConvolutionBackward0]
	129301097697280 -> 129301097697472
	129301097697280 [label=ConvolutionBackward0]
	129301097697040 -> 129301097697280
	129301097697040 [label=MaxPool2DWithIndicesBackward0]
	129301097696896 -> 129301097697040
	129301097696896 [label=NativeBatchNormBackward0]
	129301097696800 -> 129301097696896
	129301097696800 [label=GeluBackward0]
	129301097696608 -> 129301097696800
	129301097696608 [label=ConvolutionBackward0]
	129301097696512 -> 129301097696608
	129301097696512 [label=ConvolutionBackward0]
	129301097702368 -> 129301097696512
	129301097702368 [label=MaxPool2DWithIndicesBackward0]
	129301097696176 -> 129301097702368
	129301097696176 [label=NativeBatchNormBackward0]
	129301097696080 -> 129301097696176
	129301097696080 [label=GeluBackward0]
	129301097695888 -> 129301097696080
	129301097695888 [label=ConvolutionBackward0]
	129301097695792 -> 129301097695888
	129301097695792 [label=ConvolutionBackward0]
	129301097703136 -> 129301097695792
	129301097703136 [label=MaxPool2DWithIndicesBackward0]
	129301097695504 -> 129301097703136
	129301097695504 [label=NativeBatchNormBackward0]
	129301097695408 -> 129301097695504
	129301097695408 [label=GeluBackward0]
	129301097695216 -> 129301097695408
	129301097695216 [label=ConvolutionBackward0]
	129301097695120 -> 129301097695216
	129301097695120 [label=ConvolutionBackward0]
	129301097694928 -> 129301097695120
	129301097694928 [label=MaxPool2DWithIndicesBackward0]
	129301097694784 -> 129301097694928
	129301097694784 [label=NativeBatchNormBackward0]
	129301097694688 -> 129301097694784
	129301097694688 [label=GeluBackward0]
	129301097694496 -> 129301097694688
	129301097694496 [label=ConvolutionBackward0]
	129301097694400 -> 129301097694496
	129301097694400 [label=ConvolutionBackward0]
	129301097694208 -> 129301097694400
	129301298468864 [label="shared_encoder.conv_block1.sep_conv.0.weight
 (3, 1, 3, 3)" fillcolor=lightblue]
	129301298468864 -> 129301097694208
	129301097694208 [label=AccumulateGrad]
	129301097694448 -> 129301097694496
	129301298468784 [label="shared_encoder.conv_block1.sep_conv.1.weight
 (32, 3, 1, 1)" fillcolor=lightblue]
	129301298468784 -> 129301097694448
	129301097694448 [label=AccumulateGrad]
	129301097694592 -> 129301097694496
	129301298468704 [label="shared_encoder.conv_block1.sep_conv.1.bias
 (32)" fillcolor=lightblue]
	129301298468704 -> 129301097694592
	129301097694592 [label=AccumulateGrad]
	129301097694736 -> 129301097694784
	129301136503440 [label="shared_encoder.conv_block1.bn.weight
 (32)" fillcolor=lightblue]
	129301136503440 -> 129301097694736
	129301097694736 [label=AccumulateGrad]
	129301097694880 -> 129301097694784
	129301136503760 [label="shared_encoder.conv_block1.bn.bias
 (32)" fillcolor=lightblue]
	129301136503760 -> 129301097694880
	129301097694880 [label=AccumulateGrad]
	129301097694976 -> 129301097695120
	129301298468224 [label="shared_encoder.conv_block2.sep_conv.0.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	129301298468224 -> 129301097694976
	129301097694976 [label=AccumulateGrad]
	129301097695168 -> 129301097695216
	129301298468144 [label="shared_encoder.conv_block2.sep_conv.1.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	129301298468144 -> 129301097695168
	129301097695168 [label=AccumulateGrad]
	129301097695312 -> 129301097695216
	129301298468064 [label="shared_encoder.conv_block2.sep_conv.1.bias
 (64)" fillcolor=lightblue]
	129301298468064 -> 129301097695312
	129301097695312 [label=AccumulateGrad]
	129301097695456 -> 129301097695504
	129301298467984 [label="shared_encoder.conv_block2.bn.weight
 (64)" fillcolor=lightblue]
	129301298467984 -> 129301097695456
	129301097695456 [label=AccumulateGrad]
	129301097695696 -> 129301097695504
	129301298467904 [label="shared_encoder.conv_block2.bn.bias
 (64)" fillcolor=lightblue]
	129301298467904 -> 129301097695696
	129301097695696 [label=AccumulateGrad]
	129301097695600 -> 129301097695792
	129301298467184 [label="shared_encoder.conv_block3.sep_conv.0.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	129301298467184 -> 129301097695600
	129301097695600 [label=AccumulateGrad]
	129301097695840 -> 129301097695888
	129301298467424 [label="shared_encoder.conv_block3.sep_conv.1.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	129301298467424 -> 129301097695840
	129301097695840 [label=AccumulateGrad]
	129301097695984 -> 129301097695888
	129301298467344 [label="shared_encoder.conv_block3.sep_conv.1.bias
 (128)" fillcolor=lightblue]
	129301298467344 -> 129301097695984
	129301097695984 [label=AccumulateGrad]
	129301097696128 -> 129301097696176
	129301298467104 [label="shared_encoder.conv_block3.bn.weight
 (128)" fillcolor=lightblue]
	129301298467104 -> 129301097696128
	129301097696128 [label=AccumulateGrad]
	129301097696416 -> 129301097696176
	129301298467024 [label="shared_encoder.conv_block3.bn.bias
 (128)" fillcolor=lightblue]
	129301298467024 -> 129301097696416
	129301097696416 [label=AccumulateGrad]
	129301097696272 -> 129301097696512
	129301298466304 [label="shared_encoder.conv_block4.sep_conv.0.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	129301298466304 -> 129301097696272
	129301097696272 [label=AccumulateGrad]
	129301097696560 -> 129301097696608
	129301298466224 [label="shared_encoder.conv_block4.sep_conv.1.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	129301298466224 -> 129301097696560
	129301097696560 [label=AccumulateGrad]
	129301097696704 -> 129301097696608
	129301298466144 [label="shared_encoder.conv_block4.sep_conv.1.bias
 (256)" fillcolor=lightblue]
	129301298466144 -> 129301097696704
	129301097696704 [label=AccumulateGrad]
	129301097696848 -> 129301097696896
	129301298466064 [label="shared_encoder.conv_block4.bn.weight
 (256)" fillcolor=lightblue]
	129301298466064 -> 129301097696848
	129301097696848 [label=AccumulateGrad]
	129301097696992 -> 129301097696896
	129301298465984 [label="shared_encoder.conv_block4.bn.bias
 (256)" fillcolor=lightblue]
	129301298465984 -> 129301097696992
	129301097696992 [label=AccumulateGrad]
	129301097697088 -> 129301097697280
	129301094440272 [label="segment_decoder.conv_transp_block1.sep_transp_conv.0.weight
 (256, 1, 3, 3)" fillcolor=lightblue]
	129301094440272 -> 129301097697088
	129301097697088 [label=AccumulateGrad]
	129301097697376 -> 129301097697472
	129301095839472 [label="segment_decoder.conv_transp_block1.sep_transp_conv.1.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	129301095839472 -> 129301097697376
	129301097697376 [label=AccumulateGrad]
	129301097702080 -> 129301097697472
	129301142258608 [label="segment_decoder.conv_transp_block1.sep_transp_conv.1.bias
 (256)" fillcolor=lightblue]
	129301142258608 -> 129301097702080
	129301097702080 [label=AccumulateGrad]
	129301097702224 -> 129301097702320
	129301298465664 [label="segment_decoder.conv_transp_block1.bn.weight
 (256)" fillcolor=lightblue]
	129301298465664 -> 129301097702224
	129301097702224 [label=AccumulateGrad]
	129301097702272 -> 129301097702320
	129301298465584 [label="segment_decoder.conv_transp_block1.bn.bias
 (256)" fillcolor=lightblue]
	129301298465584 -> 129301097702272
	129301097702272 [label=AccumulateGrad]
	129301097702368 -> 129301097702464
	129301097702512 -> 129301097702656
	129301298463904 [label="segment_decoder.conv_transp_block2.sep_transp_conv.0.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	129301298463904 -> 129301097702512
	129301097702512 [label=AccumulateGrad]
	129301097702704 -> 129301097702752
	129301298470944 [label="segment_decoder.conv_transp_block2.sep_transp_conv.1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	129301298470944 -> 129301097702704
	129301097702704 [label=AccumulateGrad]
	129301097702848 -> 129301097702752
	129301298470864 [label="segment_decoder.conv_transp_block2.sep_transp_conv.1.bias
 (128)" fillcolor=lightblue]
	129301298470864 -> 129301097702848
	129301097702848 [label=AccumulateGrad]
	129301097702992 -> 129301097703088
	129301298463984 [label="segment_decoder.conv_transp_block2.bn.weight
 (128)" fillcolor=lightblue]
	129301298463984 -> 129301097702992
	129301097702992 [label=AccumulateGrad]
	129301097703040 -> 129301097703088
	129301298441056 [label="segment_decoder.conv_transp_block2.bn.bias
 (128)" fillcolor=lightblue]
	129301298441056 -> 129301097703040
	129301097703040 [label=AccumulateGrad]
	129301097703136 -> 129301097703232
	129301097703280 -> 129301097703424
	129301298432496 [label="segment_decoder.conv_transp_block3.sep_transp_conv.0.weight
 (192, 1, 3, 3)" fillcolor=lightblue]
	129301298432496 -> 129301097703280
	129301097703280 [label=AccumulateGrad]
	129301097703472 -> 129301097703520
	129301298432096 [label="segment_decoder.conv_transp_block3.sep_transp_conv.1.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	129301298432096 -> 129301097703472
	129301097703472 [label=AccumulateGrad]
	129301097703616 -> 129301097703520
	129301298440816 [label="segment_decoder.conv_transp_block3.sep_transp_conv.1.bias
 (64)" fillcolor=lightblue]
	129301298440816 -> 129301097703616
	129301097703616 [label=AccumulateGrad]
	129301097703952 -> 129301097704096
	129301298440736 [label="segment_decoder.conv_transp_block3.bn.weight
 (64)" fillcolor=lightblue]
	129301298440736 -> 129301097703952
	129301097703952 [label=AccumulateGrad]
	129301097703904 -> 129301097704096
	129301298432256 [label="segment_decoder.conv_transp_block3.bn.bias
 (64)" fillcolor=lightblue]
	129301298432256 -> 129301097703904
	129301097703904 [label=AccumulateGrad]
	129301097704144 -> 129301097704288
	129301298437696 [label="generative_decoder.attention_block2.query_conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	129301298437696 -> 129301097704144
	129301097704144 [label=AccumulateGrad]
	129301097704192 -> 129301097704288
	129301298443696 [label="generative_decoder.attention_block2.query_conv.bias
 (64)" fillcolor=lightblue]
	129301298443696 -> 129301097704192
	129301097704192 [label=AccumulateGrad]
	129301097704336 -> 129301097704384
	129301298437216 [label="generative_decoder.attention_block2.bn_query.weight
 (64)" fillcolor=lightblue]
	129301298437216 -> 129301097704336
	129301097704336 [label=AccumulateGrad]
	129301097704576 -> 129301097704384
	129301298443376 [label="generative_decoder.attention_block2.bn_query.bias
 (64)" fillcolor=lightblue]
	129301298443376 -> 129301097704576
	129301097704576 [label=AccumulateGrad]
	129301097704672 -> 129301097704720
	129301097704672 [label=ReshapeAliasBackward0]
	129301097704240 -> 129301097704672
	129301097704240 [label=ExpandBackward0]
	129301097704048 -> 129301097704240
	129301097704048 [label=TransposeBackward0]
	129301097703376 -> 129301097704048
	129301097703376 [label=NativeBatchNormBackward0]
	129301097702800 -> 129301097703376
	129301097702800 [label=ConvolutionBackward0]
	129301097704096 -> 129301097702800
	129301097702560 -> 129301097702800
	129301298437456 [label="generative_decoder.attention_block2.key_conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	129301298437456 -> 129301097702560
	129301097702560 [label=AccumulateGrad]
	129301097702608 -> 129301097702800
	129301298437376 [label="generative_decoder.attention_block2.key_conv.bias
 (64)" fillcolor=lightblue]
	129301298437376 -> 129301097702608
	129301097702608 [label=AccumulateGrad]
	129301097703328 -> 129301097703376
	129301298443136 [label="generative_decoder.attention_block2.bn_key.weight
 (64)" fillcolor=lightblue]
	129301298443136 -> 129301097703328
	129301097703328 [label=AccumulateGrad]
	129301097704528 -> 129301097703376
	129301298436976 [label="generative_decoder.attention_block2.bn_key.bias
 (64)" fillcolor=lightblue]
	129301298436976 -> 129301097704528
	129301097704528 [label=AccumulateGrad]
	129301097705776 -> 129301097705680
	129301097705776 [label=NativeBatchNormBackward0]
	129301097704768 -> 129301097705776
	129301097704768 [label=ConvolutionBackward0]
	129301097704096 -> 129301097704768
	129301097703568 -> 129301097704768
	129301298443456 [label="generative_decoder.attention_block2.value_conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	129301298443456 -> 129301097703568
	129301097703568 [label=AccumulateGrad]
	129301097703856 -> 129301097704768
	129301298437296 [label="generative_decoder.attention_block2.value_conv.bias
 (64)" fillcolor=lightblue]
	129301298437296 -> 129301097703856
	129301097703856 [label=AccumulateGrad]
	129301097704864 -> 129301097705776
	129301298436576 [label="generative_decoder.attention_block2.bn_value.weight
 (64)" fillcolor=lightblue]
	129301298436576 -> 129301097704864
	129301097704864 [label=AccumulateGrad]
	129301097704960 -> 129301097705776
	129301298442736 [label="generative_decoder.attention_block2.bn_value.bias
 (64)" fillcolor=lightblue]
	129301298442736 -> 129301097704960
	129301097704960 [label=AccumulateGrad]
	129301097705632 -> 129301097705488
	129301097705632 [label=NativeBatchNormBackward0]
	129301097704432 -> 129301097705632
	129301097704432 [label=GeluBackward0]
	129301097702128 -> 129301097704432
	129301097702128 [label=ConvolutionBackward0]
	129301097697184 -> 129301097702128
	129301097697184 [label=ConvolutionBackward0]
	129301097696944 -> 129301097697184
	129301097696944 [label=CatBackward0]
	129301097695936 -> 129301097696944
	129301097695936 [label=MulBackward0]
	129301097695744 -> 129301097695936
	129301097695744 [label=SoftmaxBackward0]
	129301097695360 -> 129301097695744
	129301097695360 [label=DivBackward0]
	129301097695072 -> 129301097695360
	129301097695072 [label=UnsafeViewBackward0]
	129301097694544 -> 129301097695072
	129301097694544 [label=BmmBackward0]
	129301097694832 -> 129301097694544
	129301097694832 [label=ViewBackward0]
	129301097698384 -> 129301097694832
	129301097698384 [label=ExpandBackward0]
	129301097694304 -> 129301097698384
	129301097694304 [label=NativeBatchNormBackward0]
	129301097698480 -> 129301097694304
	129301097698480 [label=ConvolutionBackward0]
	129301097703088 -> 129301097698480
	129301097698672 -> 129301097698480
	129301298438656 [label="generative_decoder.attention_block1.query_conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	129301298438656 -> 129301097698672
	129301097698672 [label=AccumulateGrad]
	129301097698624 -> 129301097698480
	129301298444816 [label="generative_decoder.attention_block1.query_conv.bias
 (128)" fillcolor=lightblue]
	129301298444816 -> 129301097698624
	129301097698624 [label=AccumulateGrad]
	129301097698432 -> 129301097694304
	129301298438336 [label="generative_decoder.attention_block1.bn_query.weight
 (128)" fillcolor=lightblue]
	129301298438336 -> 129301097698432
	129301097698432 [label=AccumulateGrad]
	129301097694352 -> 129301097694304
	129301298444496 [label="generative_decoder.attention_block1.bn_query.bias
 (128)" fillcolor=lightblue]
	129301298444496 -> 129301097694352
	129301097694352 [label=AccumulateGrad]
	129301097694640 -> 129301097694544
	129301097694640 [label=ReshapeAliasBackward0]
	129301097698528 -> 129301097694640
	129301097698528 [label=ExpandBackward0]
	129301097698720 -> 129301097698528
	129301097698720 [label=TransposeBackward0]
	129301097698816 -> 129301097698720
	129301097698816 [label=NativeBatchNormBackward0]
	129301097698912 -> 129301097698816
	129301097698912 [label=ConvolutionBackward0]
	129301097703088 -> 129301097698912
	129301097699104 -> 129301097698912
	129301298438576 [label="generative_decoder.attention_block1.key_conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	129301298438576 -> 129301097699104
	129301097699104 [label=AccumulateGrad]
	129301097699056 -> 129301097698912
	129301298438496 [label="generative_decoder.attention_block1.key_conv.bias
 (128)" fillcolor=lightblue]
	129301298438496 -> 129301097699056
	129301097699056 [label=AccumulateGrad]
	129301097698864 -> 129301097698816
	129301298444256 [label="generative_decoder.attention_block1.bn_key.weight
 (128)" fillcolor=lightblue]
	129301298444256 -> 129301097698864
	129301097698864 [label=AccumulateGrad]
	129301097694256 -> 129301097698816
	129301298438096 [label="generative_decoder.attention_block1.bn_key.bias
 (128)" fillcolor=lightblue]
	129301298438096 -> 129301097694256
	129301097694256 [label=AccumulateGrad]
	129301097696224 -> 129301097695936
	129301097696224 [label=NativeBatchNormBackward0]
	129301097695024 -> 129301097696224
	129301097695024 [label=ConvolutionBackward0]
	129301097703088 -> 129301097695024
	129301097698768 -> 129301097695024
	129301298444576 [label="generative_decoder.attention_block1.value_conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	129301298444576 -> 129301097698768
	129301097698768 [label=AccumulateGrad]
	129301097698576 -> 129301097695024
	129301298438416 [label="generative_decoder.attention_block1.value_conv.bias
 (128)" fillcolor=lightblue]
	129301298438416 -> 129301097698576
	129301097698576 [label=AccumulateGrad]
	129301097695552 -> 129301097696224
	129301298437856 [label="generative_decoder.attention_block1.bn_value.weight
 (128)" fillcolor=lightblue]
	129301298437856 -> 129301097695552
	129301097695552 [label=AccumulateGrad]
	129301097695264 -> 129301097696224
	129301298443856 [label="generative_decoder.attention_block1.bn_value.bias
 (128)" fillcolor=lightblue]
	129301298443856 -> 129301097695264
	129301097695264 [label=AccumulateGrad]
	129301097696368 -> 129301097696944
	129301097696368 [label=NativeBatchNormBackward0]
	129301097694016 -> 129301097696368
	129301097694016 [label=GeluBackward0]
	129301097699200 -> 129301097694016
	129301097699200 [label=ConvolutionBackward0]
	129301097699296 -> 129301097699200
	129301097699296 [label=ConvolutionBackward0]
	129301097699488 -> 129301097699296
	129301097699488 [label=NativeBatchNormBackward0]
	129301097699632 -> 129301097699488
	129301097699632 [label=GeluBackward0]
	129301097700832 -> 129301097699632
	129301097700832 [label=ConvolutionBackward0]
	129301097700928 -> 129301097700832
	129301097700928 [label=ConvolutionBackward0]
	129301097697040 -> 129301097700928
	129301097701120 -> 129301097700928
	129301298440256 [label="generative_decoder.conv_transp_block1.sep_transp_conv.0.weight
 (256, 1, 3, 3)" fillcolor=lightblue]
	129301298440256 -> 129301097701120
	129301097701120 [label=AccumulateGrad]
	129301097700880 -> 129301097700832
	129301298431536 [label="generative_decoder.conv_transp_block1.sep_transp_conv.1.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	129301298431536 -> 129301097700880
	129301097700880 [label=AccumulateGrad]
	129301097700736 -> 129301097700832
	129301298431456 [label="generative_decoder.conv_transp_block1.sep_transp_conv.1.bias
 (256)" fillcolor=lightblue]
	129301298431456 -> 129301097700736
	129301097700736 [label=AccumulateGrad]
	129301097699584 -> 129301097699488
	129301298431136 [label="generative_decoder.conv_transp_block1.bn.weight
 (256)" fillcolor=lightblue]
	129301298431136 -> 129301097699584
	129301097699584 [label=AccumulateGrad]
	129301097699536 -> 129301097699488
	129301298440176 [label="generative_decoder.conv_transp_block1.bn.bias
 (256)" fillcolor=lightblue]
	129301298440176 -> 129301097699536
	129301097699536 [label=AccumulateGrad]
	129301097699440 -> 129301097699296
	129301298430656 [label="generative_decoder.conv_transp_block2.sep_transp_conv.0.weight
 (256, 1, 3, 3)" fillcolor=lightblue]
	129301298430656 -> 129301097699440
	129301097699440 [label=AccumulateGrad]
	129301097699248 -> 129301097699200
	129301298439776 [label="generative_decoder.conv_transp_block2.sep_transp_conv.1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	129301298439776 -> 129301097699248
	129301097699248 [label=AccumulateGrad]
	129301097699008 -> 129301097699200
	129301298430816 [label="generative_decoder.conv_transp_block2.sep_transp_conv.1.bias
 (128)" fillcolor=lightblue]
	129301298430816 -> 129301097699008
	129301097699008 [label=AccumulateGrad]
	129301097695648 -> 129301097696368
	129301298430736 [label="generative_decoder.conv_transp_block2.bn.weight
 (128)" fillcolor=lightblue]
	129301298430736 -> 129301097695648
	129301097695648 [label=AccumulateGrad]
	129301097696032 -> 129301097696368
	129301298446256 [label="generative_decoder.conv_transp_block2.bn.bias
 (128)" fillcolor=lightblue]
	129301298446256 -> 129301097696032
	129301097696032 [label=AccumulateGrad]
	129301097696752 -> 129301097697184
	129301298430976 [label="generative_decoder.conv_transp_block3.sep_transp_conv.0.weight
 (256, 1, 3, 3)" fillcolor=lightblue]
	129301298430976 -> 129301097696752
	129301097696752 [label=AccumulateGrad]
	129301097702416 -> 129301097702128
	129301298445856 [label="generative_decoder.conv_transp_block3.sep_transp_conv.1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	129301298445856 -> 129301097702416
	129301097702416 [label=AccumulateGrad]
	129301097703184 -> 129301097702128
	129301298430416 [label="generative_decoder.conv_transp_block3.sep_transp_conv.1.bias
 (128)" fillcolor=lightblue]
	129301298430416 -> 129301097703184
	129301097703184 [label=AccumulateGrad]
	129301097705008 -> 129301097705632
	129301298439696 [label="generative_decoder.conv_transp_block3.bn.weight
 (128)" fillcolor=lightblue]
	129301298439696 -> 129301097705008
	129301097705008 [label=AccumulateGrad]
	129301097705728 -> 129301097705632
	129301298439616 [label="generative_decoder.conv_transp_block3.bn.bias
 (128)" fillcolor=lightblue]
	129301298439616 -> 129301097705728
	129301097705728 [label=AccumulateGrad]
	129301097705440 -> 129301097705392
	129301298430336 [label="generative_decoder.conv1.conv.weight
 (64, 192, 3, 3)" fillcolor=lightblue]
	129301298430336 -> 129301097705440
	129301097705440 [label=AccumulateGrad]
	129301097705200 -> 129301097705392
	129301298430176 [label="generative_decoder.conv1.conv.bias
 (64)" fillcolor=lightblue]
	129301298430176 -> 129301097705200
	129301097705200 [label=AccumulateGrad]
	129301097705104 -> 129301097693872
	129301298439536 [label="generative_decoder.conv_transp_block5.sep_transp_conv.0.weight
 (67, 1, 3, 3)" fillcolor=lightblue]
	129301298439536 -> 129301097705104
	129301097705104 [label=AccumulateGrad]
	129301097693824 -> 129301097693776
	129301298439456 [label="generative_decoder.conv_transp_block5.sep_transp_conv.1.weight
 (64, 67, 1, 1)" fillcolor=lightblue]
	129301298439456 -> 129301097693824
	129301097693824 [label=AccumulateGrad]
	129301097693680 -> 129301097693776
	129301298430256 [label="generative_decoder.conv_transp_block5.sep_transp_conv.1.bias
 (64)" fillcolor=lightblue]
	129301298430256 -> 129301097693680
	129301097693680 [label=AccumulateGrad]
	129301097693536 -> 129301097693392
	129301298445616 [label="generative_decoder.conv_transp_block5.bn.weight
 (64)" fillcolor=lightblue]
	129301298445616 -> 129301097693536
	129301097693536 [label=AccumulateGrad]
	129301097693488 -> 129301097693392
	129301298445536 [label="generative_decoder.conv_transp_block5.bn.bias
 (64)" fillcolor=lightblue]
	129301298445536 -> 129301097693488
	129301097693488 [label=AccumulateGrad]
	129301097693344 -> 129301097693296
	129301298445376 [label="generative_decoder.conv2.conv.weight
 (16, 64, 3, 3)" fillcolor=lightblue]
	129301298445376 -> 129301097693344
	129301097693344 [label=AccumulateGrad]
	129301097697568 -> 129301097693296
	129301298439136 [label="generative_decoder.conv2.conv.bias
 (16)" fillcolor=lightblue]
	129301298439136 -> 129301097697568
	129301097697568 [label=AccumulateGrad]
	129301097697712 -> 129301097697760
	129301298445216 [label="generative_decoder.conv3.conv.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	129301298445216 -> 129301097697712
	129301097697712 [label=AccumulateGrad]
	129301097697856 -> 129301097697760
	129301298439056 [label="generative_decoder.conv3.conv.bias
 (16)" fillcolor=lightblue]
	129301298439056 -> 129301097697856
	129301097697856 [label=AccumulateGrad]
	129301097697952 -> 129301097698192
	129301298438976 [label="generative_decoder.conv1x1.conv.weight
 (3, 16, 1, 1)" fillcolor=lightblue]
	129301298438976 -> 129301097697952
	129301097697952 [label=AccumulateGrad]
	129301097698000 -> 129301097698048
	129301298445136 [label="generative_decoder.conv1x1.bn.weight
 (3)" fillcolor=lightblue]
	129301298445136 -> 129301097698000
	129301097698000 [label=AccumulateGrad]
	129301097698096 -> 129301097698048
	129301298445056 [label="generative_decoder.conv1x1.bn.bias
 (3)" fillcolor=lightblue]
	129301298445056 -> 129301097698096
	129301097698096 [label=AccumulateGrad]
	129301097698336 -> 129301091126384
}

{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T07:32:11.072104Z",
     "start_time": "2024-07-02T07:32:11.069006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from model import InpainTor\n",
    "from losses import CompositeLoss\n",
    "from dataset import RORDDataset\n",
    "import optuna"
   ],
   "id": "250502cef7e0f98b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T07:32:13.180967Z",
     "start_time": "2024-07-02T07:32:13.174212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset directory configuration\n",
    "external_disk_path = \"/media/tiagociiic/easystore\"\n",
    "split = 'debug'\n",
    "dataset_dir = os.path.join(external_disk_path, \"RORD\")\n",
    "train_dir = os.path.join(dataset_dir, split)\n",
    "print(f\"Dataset directory: {dataset_dir}\")"
   ],
   "id": "52f9fb15a939cda5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /media/tiagociiic/easystore/RORD\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T07:33:09.010092Z",
     "start_time": "2024-07-02T07:32:19.408685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = RORDDataset(root_dir=dataset_dir, split='debug', image_size=[512, 512])\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        inputs, seg_gt, inpaint_gt = [batch[k].to(device) for k in ['image', 'mask', 'gt']]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, seg_gt, inpaint_gt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model = InpainTor().to(device)\n",
    "    criterion = CompositeLoss(seg_loss=torch.nn.NLLLoss(), inpaint_loss=torch.nn.MSELoss(), lambda_=0.5)\n",
    "\n",
    "    # Suggested learning rate\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 1e-1)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train the model\n",
    "    n_epochs = 3\n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        loss = train_epoch(model, optimizer, criterion, train_loader)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return sum(losses) / len(losses)  # Loss averaged over all epochs\n",
    "\n",
    "\n",
    "# Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Best learning rate and loss\n",
    "best_lr = study.best_params['lr']\n",
    "best_loss = study.best_value\n",
    "\n",
    "print(f\"Best learning rate: {best_lr}\")\n",
    "print(f\"Best loss: {best_loss}\")\n",
    "\n",
    "final_model = InpainTor().to(device)\n",
    "final_optimizer = optim.AdamW(final_model.parameters(), lr=best_lr)"
   ],
   "id": "99eb100479ecf5fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-02 08:32:19.417\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdataset\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m94\u001B[0m - \u001B[1mLoading image, ground truth, and mask files...\u001B[0m\n",
      "\u001B[32m2024-07-02 08:32:19.419\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdataset\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m99\u001B[0m - \u001B[1mLoading image files from: /media/tiagociiic/easystore/RORD/debug/img, ground truth files from: /media/tiagociiic/easystore/RORD/debug/gt, and mask files from: /media/tiagociiic/easystore/RORD/debug/multiclass_mask\u001B[0m\n",
      "\u001B[32m2024-07-02 08:32:19.422\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdataset\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m110\u001B[0m - \u001B[1mFound 10 image files\u001B[0m\n",
      "\u001B[32m2024-07-02 08:32:19.422\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdataset\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m111\u001B[0m - \u001B[1mFound 10 ground truth files\u001B[0m\n",
      "\u001B[32m2024-07-02 08:32:19.422\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdataset\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m112\u001B[0m - \u001B[1mFound 10 mask files\u001B[0m\n",
      "\u001B[32m2024-07-02 08:32:19.423\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdataset\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m133\u001B[0m - \u001B[1mFound 10 image files, 10 ground truth files, and 10 mask files\u001B[0m\n",
      "\u001B[32m2024-07-02 08:32:19.423\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdataset\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m140\u001B[0m - \u001B[1mFound 10 common files in the directories\u001B[0m\n",
      "\u001B[32m2024-07-02 08:32:19.425\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdataset\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m162\u001B[0m - \u001B[1mFound 10 valid samples out of 10 total samples\u001B[0m\n",
      "[I 2024-07-02 08:32:19,425] A new study created in memory with name: no-name-653c1c8a-59c8-44fd-b72a-aa5beb1f4b7e\n",
      "[I 2024-07-02 08:32:22,141] Trial 0 finished with value: 2.113578306304084 and parameters: {'lr': 0.024854095588141997}. Best is trial 0 with value: 2.113578306304084.\n",
      "[I 2024-07-02 08:32:24,582] Trial 1 finished with value: 1.99194590250651 and parameters: {'lr': 0.06256111017369241}. Best is trial 1 with value: 1.99194590250651.\n",
      "[I 2024-07-02 08:32:27,089] Trial 2 finished with value: 2.2727016607920327 and parameters: {'lr': 0.004368578829335376}. Best is trial 1 with value: 1.99194590250651.\n",
      "[I 2024-07-02 08:32:29,565] Trial 3 finished with value: 1.8983987702263725 and parameters: {'lr': 0.08780075095455686}. Best is trial 3 with value: 1.8983987702263725.\n",
      "[I 2024-07-02 08:32:32,012] Trial 4 finished with value: 1.92773257361518 and parameters: {'lr': 0.08307622589320916}. Best is trial 3 with value: 1.8983987702263725.\n",
      "[I 2024-07-02 08:32:34,455] Trial 5 finished with value: 2.1310728655921087 and parameters: {'lr': 0.029821199649823497}. Best is trial 3 with value: 1.8983987702263725.\n",
      "[I 2024-07-02 08:32:36,896] Trial 6 finished with value: 2.0890013641781278 and parameters: {'lr': 0.03385016226863207}. Best is trial 3 with value: 1.8983987702263725.\n",
      "[I 2024-07-02 08:32:39,327] Trial 7 finished with value: 2.2836095756954617 and parameters: {'lr': 0.003586438544297032}. Best is trial 3 with value: 1.8983987702263725.\n",
      "[I 2024-07-02 08:32:41,781] Trial 8 finished with value: 2.0761558877097235 and parameters: {'lr': 0.044527303146336634}. Best is trial 3 with value: 1.8983987702263725.\n",
      "[I 2024-07-02 08:32:44,274] Trial 9 finished with value: 1.9090820418463814 and parameters: {'lr': 0.07240549546813674}. Best is trial 3 with value: 1.8983987702263725.\n",
      "[I 2024-07-02 08:32:46,715] Trial 10 finished with value: 1.8948131534788344 and parameters: {'lr': 0.09696641099613436}. Best is trial 10 with value: 1.8948131534788344.\n",
      "[I 2024-07-02 08:32:49,191] Trial 11 finished with value: 1.8408315844006007 and parameters: {'lr': 0.09806447731899928}. Best is trial 11 with value: 1.8408315844006007.\n",
      "[I 2024-07-02 08:32:51,625] Trial 12 finished with value: 1.8825117217169869 and parameters: {'lr': 0.0997996607783953}. Best is trial 11 with value: 1.8408315844006007.\n",
      "[I 2024-07-02 08:32:54,108] Trial 13 finished with value: 1.9119056860605879 and parameters: {'lr': 0.09753458970496996}. Best is trial 11 with value: 1.8408315844006007.\n",
      "[I 2024-07-02 08:32:56,584] Trial 14 finished with value: 1.970773153834873 and parameters: {'lr': 0.06435145577162285}. Best is trial 11 with value: 1.8408315844006007.\n",
      "[I 2024-07-02 08:32:59,049] Trial 15 finished with value: 1.9208297729492188 and parameters: {'lr': 0.08188913892427553}. Best is trial 11 with value: 1.8408315844006007.\n",
      "[I 2024-07-02 08:33:01,524] Trial 16 finished with value: 1.9481142626868353 and parameters: {'lr': 0.0716687702052149}. Best is trial 11 with value: 1.8408315844006007.\n",
      "[I 2024-07-02 08:33:04,029] Trial 17 finished with value: 1.9146936337153118 and parameters: {'lr': 0.09985009902939566}. Best is trial 11 with value: 1.8408315844006007.\n",
      "[I 2024-07-02 08:33:06,516] Trial 18 finished with value: 2.036108043458727 and parameters: {'lr': 0.05230956209411342}. Best is trial 11 with value: 1.8408315844006007.\n",
      "[I 2024-07-02 08:33:08,998] Trial 19 finished with value: 1.8725970851050484 and parameters: {'lr': 0.08732047080858232}. Best is trial 11 with value: 1.8408315844006007.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.09806447731899928\n",
      "Best loss: 1.8408315844006007\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
